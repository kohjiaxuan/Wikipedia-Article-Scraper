{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #Get the HTML code\n",
    "from bs4 import BeautifulSoup #Tidy up the code\n",
    "from collections import Counter #Counter to count occurances of each word\n",
    "import matplotlib.pyplot as plt #graph plotting\n",
    "import re #regular expression to check if language setting is exactly 2 letters (for non common langs) in the argument\n",
    "import os #for plotwords to tell where file is saved\n",
    "\n",
    "class wiki:\n",
    "\n",
    "    #the main features of cleaning the wiki site and whether the site is valid is run in __init__\n",
    "    \n",
    "    def __init__(self,title,option='No',lang='en',checknltk='No'):\n",
    "        #print(\"Page is loading...\\n\")\n",
    "\n",
    "        if isinstance(title, str) == True:\n",
    "            if str(option).lower() == 'yes' or str(option) == '':\n",
    "                self.title = str(title.title()) #title on LHS is variable input, RHS is function for proper case/title case\n",
    "                #print(\"Search text formatted to title/proper case by default. Set second argument as 'No' to disable formatting\")\n",
    "            elif str(option).lower() == 'no':\n",
    "                #print(\"Search text has preserved the cases of each letter. Set second argument as 'Yes' to format to title/proper case\")\n",
    "                self.title = title\n",
    "            else:\n",
    "                self.title = title.title() #title on LHS is variable input, RHS is function for proper case/title case\n",
    "                print('Invalid option for preserving case of search text, title/proper case will be used by default')\n",
    "            #As long as title is string, regardless of option the replacement for title for URL can be done\n",
    "            self.title = str(self.title.replace(\" \", \"_\")) #Convert spaces to _ as is Wikipedia page format\n",
    "        else:\n",
    "            print('Error encountered, search text (first argument) is not written as a string with quotes. Please try again')\n",
    "        \n",
    "        \n",
    "        #Checking if you should use NLTK library, default set to False\n",
    "        self.nltkrun = False #default is don't use it for stoplist\n",
    "        if isinstance(checknltk, str): #check for string yes, no and other permutations\n",
    "            if checknltk.lower().strip() in {'yes','true','y','t'}:\n",
    "                import nltk\n",
    "                nltk.download('stopwords')\n",
    "                nltk.download('wordnet')\n",
    "                from nltk.corpus import stopwords\n",
    "                from nltk.corpus import wordnet\n",
    "                self.nltkrun = True\n",
    "            elif checknltk.lower().strip() in {'no','false','n','f','na','n/a','nan'}:\n",
    "                self.nltkrun = False\n",
    "            else:\n",
    "                self.nltkrun = False\n",
    "        elif isinstance(checknltk, bool): #check for boolean yes/no\n",
    "            if checknltk == True:\n",
    "                import nltk\n",
    "                nltk.download('stopwords')\n",
    "                nltk.download('wordnet')\n",
    "                from nltk.corpus import stopwords\n",
    "                from nltk.corpus import wordnet\n",
    "                self.nltkrun = True\n",
    "            else:\n",
    "                self.nltkrun = False\n",
    "        else: #run default if options are invalid - don't run nltk stoplist\n",
    "            self.nltkrun = False\n",
    "\n",
    "        #Default: Stopword list obtained from nltk\n",
    "        self.nltkstopword = []\n",
    "        \n",
    "        #Detect language settings in third argument\n",
    "        self.lang = 'en'  \n",
    "        \n",
    "        \n",
    "        self.url = 'https://' + self.lang + '.wikipedia.org/wiki/' + self.title #combine the two to get full URL\n",
    "\n",
    "        try: \n",
    "            self.page = requests.get(self.url) #retrieve HTML info from site\n",
    "        except:\n",
    "            self.lang = 'en'\n",
    "            self.url = 'https://' + self.lang + '.wikipedia.org/wiki/' + self.title\n",
    "            self.page = requests.get(self.url)\n",
    "            print('Error with language settings, English used as default\\n')\n",
    "\n",
    "        self.contents = self.page.content \n",
    "        self.soup = BeautifulSoup(self.contents, 'html.parser') #Parse the HTML nicely with formatting\n",
    "        \n",
    "        \n",
    "        self.trancetext = self.soup.find_all('p') #obtain all paragraphs starting with tag <p>\n",
    "        self.trancetext2 = self.soup.find_all('li') #obtain all paragraphs starting with tag <li>\n",
    "\n",
    "        #get paragraphs from trancetext with special format into a list\n",
    "        self.para=[]\n",
    "        for paragraph in self.trancetext: #append paragraphs starting with <p>\n",
    "            self.para.append(paragraph)\n",
    "\n",
    "        self.relatedtopic = \",*RELATED WIKI TOPIC*\" #to add to points with a link and are on sidebar\n",
    "        for paragraph in self.trancetext2: #append paragraphs starting with <li>\n",
    "            if str(paragraph).find('<li><a href=') != -1:\n",
    "                if str(paragraph).find('</a></li>') != -1 or str(paragraph).find('</a></sup></li>') != -1: \n",
    "                    self.para.append(self.relatedtopic)\n",
    "            if str(paragraph).find('toctext') == -1: #remove Wiki headers 1.2.3 with toctext as they can't be arranged properly\n",
    "                self.para.append(paragraph)\n",
    "    \n",
    "        #REASON WHY WE HAVE TO DO TWO FOR LOOPS WITH TWO TRANCETEXT IS BECAUSE THE FIND_ALL FOR ARRAY IS NOT IN ORDER\n",
    "        #COMMENCE CLEANING OF NONSENSE HTML <> and WIKI LINK [no]\n",
    "        \n",
    "        #For FIXING the summary function\n",
    "        self.troubleshoot = self.para\n",
    "        \n",
    "        self.para = list(str(self.para)) #chop everything into letters for cleaning\n",
    "        \n",
    "        #This block of code removes the first letter [, removes any words with <> html tag or [] citation\n",
    "        #When it detects a <li> it will create two blanks\n",
    "        self.start = 0 #is letter currently inside tag <>\n",
    "        self.end = 0 #has <> just ended, need to check for , if it just ended to not copy a comma after <>\n",
    "        self.first = 1 #first letter is [, need to omit\n",
    "        self.bracket = 0 #check if letter is inside bracket\n",
    "        self.li = 0 #check for <li> to line break\n",
    "        self.p = 0 #check for <p> to line break\n",
    "        self.point = 0 #after <li>, puts a • before adding new letter\n",
    "        self.para2 = []\n",
    "        for letter in self.para:\n",
    "            if self.first == 0:\n",
    "                if letter == '<': #tells python to stop reading letters inside a bracket\n",
    "                    self.start = 1\n",
    "                elif letter == '>': #next letter can be read since its out of bracket, unless its another <\n",
    "                    self.start = 0\n",
    "                    self.end = 1\n",
    "                elif self.end == 1 and letter == ',': #skip COMMA reading when it occurs like </p>, at end of para\n",
    "                    self.end = 0\n",
    "                    continue\n",
    "                elif letter == '[':\n",
    "                    self.bracket = 1\n",
    "                    self.end = 0\n",
    "                elif letter == ']':\n",
    "                    self.bracket = 0\n",
    "                    self.end = 0\n",
    "                elif self.start == 0 and self.bracket == 0: #ALL CLEAR TO READ LETTER\n",
    "                    self.end = 0\n",
    "                    if self.point == 1:\n",
    "                        self.para2.append('• ')\n",
    "                        self.point = 0\n",
    "                    self.para2.append(letter)\n",
    "            if letter == '<':\n",
    "                self.li = 1\n",
    "            elif letter != 'l' and self.li == 1:\n",
    "                self.li = 0\n",
    "            elif letter == 'l' and self.li == 1:\n",
    "                self.li = 2\n",
    "            elif letter == 'i' and self.li == 2:\n",
    "                self.li = 3\n",
    "            elif letter != '>' and self.li == 3:\n",
    "                self.li = 0\n",
    "            elif letter == '>' and self.li == 3:\n",
    "                self.para2.append('\\n\\n')\n",
    "                self.li = 0\n",
    "                self.point = 1\n",
    "            if letter == '<':\n",
    "                self.p = 1\n",
    "            elif letter != 'p' and self.p == 1:\n",
    "                self.p = 0\n",
    "            elif letter == 'p' and self.p == 1:\n",
    "                self.p = 2\n",
    "            elif letter == '>' and self.p == 2:\n",
    "                self.para2.append('\\n')\n",
    "                self.p = 0\n",
    "            self.first = 0 #Had an issue with the first letter being [, after skipping this, the [number] checks can run\n",
    "\n",
    "        self.para2=''.join(self.para2) #combine back all letters and spaces\n",
    "        #REMOVE UNWANTED ARRAYS\n",
    "        self.para1 = []\n",
    "        \n",
    "        \n",
    "        #WORD COUNT (SELF.PARA3) AND COMMON WORDS (SELF.TRANCECOUNTER)\n",
    "        \n",
    "        self.para3 = self.para2.split() #split paragraphs into words again for counting\n",
    "        self.niceword = ''\n",
    "        self.punctuation = ('.',',','(',')','\"',\"'\",'?','!','*','|',':',';')\n",
    "        for index, word in enumerate(self.para3):\n",
    "            self.niceword = word\n",
    "            self.niceword = self.niceword.lower() #standardize all to lower case before counting\n",
    "            for punctuation in self.punctuation:\n",
    "                self.niceword = self.niceword.replace(punctuation,'') #clean up bad punctuation\n",
    "            self.para3[index] = self.niceword \n",
    "        self.trancecounter = Counter(self.para3) \n",
    "        #counter solely used for word count, cannot be used as banlist not implemented yet. \n",
    "        #Make new trancecounter2+banlist for use\n",
    "        self.allwords = dict(self.trancecounter.most_common()) \n",
    "        #convert to dictionary so that for loop can extract words + do unique word count + total word count\n",
    "        \n",
    "        self.trancelist = [] #full list of words to fill up, cannot be used yet as banlist not implemented\n",
    "        \n",
    "        #FIND OUT UNIQUE WORD COUNT AND TOTAL WORD COUNT BEFORE BANLIST\n",
    "        self.fullcount = 0\n",
    "        self.fullwords = 0\n",
    "        for key in self.allwords:\n",
    "            self.fullcount += self.allwords[key]\n",
    "            self.fullwords += 1\n",
    "            self.trancelist.append(key)\n",
    "        \n",
    "        #IMPLEMENT BAN LIST (FROM WIKIPEDIA) BY DEL FUNCTION FOR COUNTER TRANCECOUNT AND WORD LIST SELF.TRANCELIST\n",
    "        #BAN YEARS AND NUMBERS\n",
    "        banlist = ('the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'I', 'it', 'for', 'not', 'on', 'with', \n",
    "                   'he', 'as', 'you', 'do', 'at', 'this', 'but', 'his', 'by', 'from', 'they', 'we', 'say', 'her', 'she', \n",
    "                   'or', 'an', 'will', 'my', 'one', 'all', 'would', 'there', 'their', 'what', 'so', 'up', 'out', 'if', \n",
    "                   'about', 'who', 'get', 'which', 'go', 'me', 'when', 'make', 'can', 'like', 'time', 'no', 'just', \n",
    "                   'him', 'know', 'take', 'people', 'into', 'year', 'your', 'good', 'some', 'could', 'them', 'see', \n",
    "                   'other', 'than', 'then', 'now', 'look', 'only', 'come', 'its', 'over', 'think', 'also', 'back', \n",
    "                   'after', 'use', 'two', 'how', 'our', 'work', 'first', 'well', 'way', 'even', 'new', 'want','topic', \n",
    "                   'because', 'any', 'these', 'give', 'day', 'most', 'us','retrieved','^','archived',\"•\",'related',\n",
    "                   \"',*related\",\"wiki\",\"topic*',\",\"is\",\"are\",'was','since','such','articles','has','&amp;','&amp',\n",
    "                   'p','b','january','february','march','april','may','june','july','august','september','october',\n",
    "                   'november','december','2019','2018','2017','2016','2015','2014','2013','2012','2011','2010','2009',\n",
    "                   '&amp','1','2','3','4','5','2008','2007','2006','2005','2004','2003','2002','2001','2000',\n",
    "                  '6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26',\n",
    "                  '27','28','29','30','original','isbn','wikipedia')\n",
    "        \n",
    "        #English banlist from top 100 common words and some extra terms\n",
    "        if self.lang == 'en':\n",
    "            for word in banlist: #delete words in counter and list only if it's in english\n",
    "                del self.trancecounter[word]\n",
    "                self.allwords.pop(word, None)\n",
    "            \n",
    "        #If NLTK stoplist is used, delete words from their stoplist as well\n",
    "        if self.nltkrun == True:\n",
    "            for word in self.nltkstopword: #delete words in counter and list\n",
    "                del self.trancecounter[word]\n",
    "                self.allwords.pop(word, None)\n",
    "            \n",
    "        #DELETE '',.,·,•,↑,space,null,related,wiki,common from counter and dictionary\n",
    "        del self.trancecounter[\"''\"]\n",
    "        self.allwords.pop(\"''\", None)\n",
    "        del self.trancecounter[\".\"]\n",
    "        self.allwords.pop(\".\", None)\n",
    "        del self.trancecounter[\"·\"]\n",
    "        self.allwords.pop(\"·\", None)\n",
    "        del self.trancecounter[\"•\"]\n",
    "        self.allwords.pop(\"•\", None)\n",
    "        del self.trancecounter[\"↑\"]\n",
    "        self.allwords.pop(\"↑\", None)\n",
    "        del self.trancecounter[\" \"]\n",
    "        self.allwords.pop(\" \", None)\n",
    "        del self.trancecounter[\"\"]\n",
    "        self.allwords.pop(\"\", None)\n",
    "        del self.trancecounter[\"-\"]\n",
    "        self.allwords.pop(\"-\", None)\n",
    "        del self.trancecounter[\"–\"]\n",
    "        self.allwords.pop(\"–\", None)\n",
    "        del self.trancecounter[\"related\"]\n",
    "        self.allwords.pop(\"related\", None)\n",
    "        del self.trancecounter[\"wiki\"]\n",
    "        self.allwords.pop(\"wiki\", None)\n",
    "        del self.trancecounter[\"common\"]\n",
    "        self.allwords.pop(\"common\", None)\n",
    "        \n",
    "        #FIND OUT TOTAL WORD COUNT AFTER BANLIST FOR FUNCTION COMMONWORDPCT THAT USES PERCENTAGE OF THRESHOLD FOR WORD COUNT\n",
    "        self.fullcount2 = 0\n",
    "        self.fullwords2 = 0\n",
    "        \n",
    "        self.trancelist2 = [] #NOT USED!!\n",
    "        \n",
    "        for key in self.allwords: #SELF.ALLWORDS HAVE WORDS REMOVED ON ITSELF VIA BANLIST, DONT NEED NEW VARIABLE\n",
    "            self.fullcount2 += self.allwords[key] #FULLCOUNT2 used for COMMONWORDPCT and TOTAL WORDS function to show total word count aft removing banlist\n",
    "            self.fullwords2 += 1 #FULLWORDS2 used in TOTAL WORDS function to show unique word count aft removing banlist\n",
    "            self.trancelist2.append(key) #NOT USED!!!\n",
    "    \n",
    "    \n",
    "        #This section checks if the Wiki site was loaded successfully..\n",
    "        self.missing = self.soup.find_all('b') \n",
    "        #Wikipedia does not have an article with this exact name.\n",
    "        #This sentence that always appears for Error 404 pages, is bolded, so <b> tag can help to find it\n",
    "                \n",
    "        #Check for sentence that tells of Error 404 website using a counter.\n",
    "        self.goodsite = 1\n",
    "        self.offsite = 0\n",
    "        \n",
    "        for sentence in self.trancetext: #check if a site goes through but it is an ambiguous site (recommendations page)\n",
    "            #refer to: phrase belongs in a <p> paragraph\n",
    "            if str(sentence).find(\"refer to:\") != -1:\n",
    "                self.offsite = 1            \n",
    "        \n",
    "        for sentence in self.missing: #RUN THROUGH EVERY ELEMENT IN LIST\n",
    "            if str(sentence) == \"<b>Wikipedia does not have an article with this exact name.</b>\": #CONVERT ELEMENT TO STRING TYPE BEFORE CHECK!!!\n",
    "                self.goodsite = 0 #sentence exists, bad site means counter flips to 0\n",
    "        \n",
    "        if self.goodsite == 1 and self.offsite == 0:\n",
    "            #print('Wikipedia page loaded successfully!! Type variablename.HELP() for documentation of functions.')\n",
    "        \n",
    "            #WHEN SEARCH IS SUCCESSFUL, PRINT 2 PARAGRAPHS FOR PREVIEW\n",
    "            self.parashort = []\n",
    "            self.noofpara = 0\n",
    "            for paragraph in self.trancetext: #append ONLY 2 paragraphs starting with <p>\n",
    "                if self.noofpara < 2 and str(paragraph) != '<p class=\"mw-empty-elt\">\\n</p>' and len(str(paragraph)) > 199: \n",
    "                    self.parashort.append(paragraph)\n",
    "                    self.noofpara += 1\n",
    "\n",
    "            self.parashort = list(str(self.parashort)) #chop everything into letters for usage\n",
    "            self.start = 0 #is letter currently inside tag <>\n",
    "            self.end = 0 #has <> just ended, need to check for , if it just ended to not copy a comma after <>\n",
    "            self.first = 1 #first letter is [, need to omit\n",
    "            self.bracket = 0 #check if letter is inside bracket\n",
    "            self.li = 0 #check for <li> to line break\n",
    "            self.p = 0 #check for <p> to line break\n",
    "            self.parashort2 = []\n",
    "            for letter in self.parashort:\n",
    "                if self.first == 0:\n",
    "                    if letter == '<': #tells python to stop reading letters inside a bracket\n",
    "                        self.start = 1\n",
    "                    elif letter == '>': #next letter can be read since its out of bracket, unless its another <\n",
    "                        self.start = 0\n",
    "                        self.end = 1\n",
    "                    elif self.end == 1 and letter == ',': #skip COMMA reading when it occurs like </p>, at end of para\n",
    "                        self.end = 0\n",
    "                        continue\n",
    "                    elif letter == '[':\n",
    "                        self.bracket = 1\n",
    "                        self.end = 0\n",
    "                    elif letter == ']':\n",
    "                        self.bracket = 0\n",
    "                        self.end = 0\n",
    "                    elif self.start == 0 and self.bracket == 0: #ALL CLEAR TO READ LETTER\n",
    "                        self.end = 0\n",
    "                        self.parashort2.append(letter)\n",
    "                if letter == '<':\n",
    "                    self.p = 1\n",
    "                elif letter != 'p' and self.p == 1:\n",
    "                    self.p = 0\n",
    "                elif letter == 'p' and self.p == 1:\n",
    "                    self.p = 2\n",
    "                elif letter == '>' and self.p == 2:\n",
    "                    self.parashort2.append('\\n\\n')\n",
    "                    self.p = 0\n",
    "                self.first = 0 #Had an issue with the first letter being [, after skipping this, the [number] checks can run\n",
    "\n",
    "            self.parashort2=''.join(self.parashort2) #combine back all letters and spaces\n",
    "            #REMOVE UNWANTED ARRAYS\n",
    "            self.parashort = []        \n",
    "\n",
    "            #END OF DATA PROCESSING FOR AUTOMATIC SUMMARY PRINTED WHEN SEARCHING\n",
    "\n",
    "            #print(self.parashort2)\n",
    "            #print two paragraphs when search is successful, disabled\n",
    "            \n",
    "        elif self.goodsite == 1 and self.offsite == 1:\n",
    "            print('\\nThe title \"'+ self.title.replace(\"_\", \" \") + '\" you specified is ambiguous. As a result, you are linked to a clarification page.\\n\\n')\n",
    "            print('Here are some suggestions to use: \\n')\n",
    "            \n",
    "            self.all_links = self.soup.find_all(\"a\") #ALL HTML TAGS STARTING WITH <A, E.G. <A HREF, <A TITLE AND FULL PARAGRAPH\n",
    "            self.wiktwords = []\n",
    "            for link in self.all_links:\n",
    "                self.wiktwords.append(link.get(\"title\")) #TAG STARTING WITH A, CONTENT ENCLOSED INSIDE TITLE=\"\"\n",
    "                #print(link.get(\"title\")) #shows list of items appended, common words all start with wikt:\n",
    "\n",
    "            self.cleanlink = []\n",
    "            for words in self.wiktwords: \n",
    "                self.words2 = str(words) #words are not string yet so need str function before saving into new var\n",
    "                self.cleanlink.append(self.words2)\n",
    "#                 if self.words2.find(\"wiktionary:\") != -1:\n",
    "#                     self.tempsliceword = list(str(self.words2))\n",
    "#                     self.newword = []\n",
    "#                     self.x = 0\n",
    "#                     for letter in self.tempsliceword:\n",
    "#                         if self.x > 10:\n",
    "#                             self.newword.append(letter)\n",
    "#                         self.x += 1\n",
    "#                     self.cleanword = ''.join(self.newword)\n",
    "#                     self.cleanlink.append(self.cleanword)\n",
    "#                 elif self.words2 != 'None':\n",
    "#                     self.cleanlink.append(self.words2)\n",
    "\n",
    "            for link in self.cleanlink:\n",
    "                if link.find(\"Help:\") != -1:\n",
    "                    break\n",
    "                elif link.find(\"Edit section:\") != -1:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(link)\n",
    "            \n",
    "        else:\n",
    "            print('Wikipedia page could not be found for \"' + str(self.title.replace(\"_\", \" \")) + '\". Please try again!') \n",
    "            print('Other useful information: Enclose title argument with single quotes. Spaces are allowed, and title is case insensitive.')\n",
    "        \n",
    "    \n",
    "    def gettext(self,outfull='No'): #comes after init\n",
    "        if isinstance(outfull, str): #check for string yes, no and other permutations\n",
    "            if outfull.lower().strip() in {'yes','true','y','t'}:\n",
    "                print(\"Full text is output. To print it instead, put 'no' in argument\")\n",
    "                return self.para2\n",
    "            elif outfull.lower().strip() in {'no','false','n','f','na','n/a','nan'}:\n",
    "                print(\"Full text is printed. To set as output, put 'yes' in argument\")\n",
    "                print(self.para2)\n",
    "            else:\n",
    "                print(\"Full text is invalid, summary is printed by default. To set as output, put 'yes' in argument\")\n",
    "                print(self.para2)\n",
    "        elif isinstance(outfull, bool): #check for boolean yes/no\n",
    "            if outfull == True:\n",
    "                print(\"Full text is output. To print it instead, put False or 'no' in argument\")\n",
    "                return self.para2\n",
    "            else:\n",
    "                print(\"Full text is printed. To set as output, put True or 'yes' in argument\")\n",
    "                print(self.para2)   \n",
    "        else: #run default - print if invalid option\n",
    "            print(\"2nd argument not a string, full text is printed by default. To set as output, put 'yes' in argument\")\n",
    "            print(self.para2)\n",
    "\n",
    "        \n",
    "    def commonwords(self,wordcount=100):\n",
    "        self.wordcount = 100\n",
    "        if wordcount != 100 and isinstance(wordcount, int) == True:\n",
    "            self.wordcount = wordcount\n",
    "        elif wordcount != 100 and isinstance(wordcount, int) == False:\n",
    "            print('Word count specified is currently not an integer. Hence default of 100 words is used\\n')\n",
    "        #convert counter to list to dictionary then sum up total word count using for loop in word[key]\n",
    "        self.topwords = dict(self.trancecounter.most_common(self.wordcount))\n",
    "        return self.topwords\n",
    "\n",
    "    def plotwords(self,wordcount2=20):\n",
    "        self.wordcount2 = 20\n",
    "        if wordcount2 != 20 and isinstance(wordcount2, int) == True:\n",
    "            self.wordcount2 = wordcount2\n",
    "        elif wordcount2 != 20 and isinstance(wordcount2, int) == False:\n",
    "            print('Word count specified is currently not an integer. Hence default of 20 words is used for graph\\n')\n",
    "        #convert counter to list to dictionary then sum up total word count using for loop in word[key]\n",
    "        self.topwords2 = dict(self.trancecounter.most_common(self.wordcount2))\n",
    "        \n",
    "        #matplotlib.pyplot.bar(range, height, tick_label)\n",
    "        self.wordnames = list(self.topwords2.keys())\n",
    "        self.wordvalues = list(self.topwords2.values())\n",
    "\n",
    "        #tick_label does the some work as plt.xticks()\n",
    "        plt.figure(figsize=(22, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        plt.bar(range(len(self.topwords2)),self.wordvalues,tick_label=self.wordnames)\n",
    "        plt.savefig('wordcount.png')\n",
    "        plt.rcParams['figure.figsize'] = [22, 12]\n",
    "        plt.show()\n",
    "        \n",
    "        self.cwd = os.getcwd()\n",
    "        return 'Graph is saved as wordcount.png in directory: ' + str(self.cwd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
